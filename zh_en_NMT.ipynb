{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zh-en NMT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzbxzZOSetwkXYzXCdqHwC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevvvvvvin/zh-cn-NMT/blob/master/zh_en_NMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If531MQtvVx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL6k9B7IqMYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # 在单词与跟在其后的标点符号之间插入一个空格\n",
        "    # 例如： \"he is a boy.\" => \"he is a boy .\"\n",
        "    # 参考：https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub('([.,!?()])', r' \\1 ', w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # 除了 (a-z, A-Z, \".\", \"?\", \"!\", \",\")，将所有字符替换为空格\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # 给句子加上开始和结束标记\n",
        "    # 以便模型知道何时开始和结束预测\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "def preprocess_sentence_zh(w):\n",
        "    \n",
        "    all_punc= \"、【 】 “”：；（）《》‘’{}⑦()、%^>℃：.”“^-——=&#@￥\"\n",
        "    w = u\" \".join(jieba.cut(w,cut_all=True))\n",
        "    w2=[]\n",
        "    for i in w:\n",
        "        w2.append(i)\n",
        "        if i in all_punc:\n",
        "            w2.remove(i)\n",
        "    w2 = ''.join(w2)\n",
        "    w2 = u\" \".join(jieba.cut(w2,cut_all=True))\n",
        "    w2 = '<start> ' + w + ' <end>'\n",
        "    return w2\n",
        "\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0TSbMNcqyVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1216ec6e-8abe-43ba-da9e-ae1271d6d220"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "zh_sentence = u\"我可以借你的书吗？\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence_zh(zh_sentence))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.989 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<start> 我 可以 借 你 的 书 吗 ？ <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti8ChHu429FT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    s = [[w for w in l.split('\\t')] for l in lines[:num_examples]]\n",
        "    word_pairs = [[preprocess_sentence(w[0]),preprocess_sentence_zh(w[1])] for w in s]  \n",
        "    print(zip(*word_pairs))\n",
        "    return zip(*word_pairs)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clhnn1re2_N3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "066263e9-312f-440c-d513-ee929977a7d1"
      },
      "source": [
        "en, zh = create_dataset('cmn.txt', None)\n",
        "print(en[-1])\n",
        "print(zh[-1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<zip object at 0x7f0387df3708>\n",
            "<start> if a person has not had a chance to acquire his target language by the time he s an adult , he s unlikely to be able to reach native speaker level in that language . <end>\n",
            "<start> 如果 一 個 人 在 成人 前 沒 有 機 會 習 得 目 標 語 言 ， 他 對 該 語 言 的 認 識 達 到 母 語 者 程度 的 機 會 是 相 當 小 的 。 <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP1U4g1aTk4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw54THtiTmvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq2VQ14kTrZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "    # 创建清理过的输入输出对\n",
        "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9557EXTgTwD4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94a92a21-93ad-479d-e4f2-0d0221dbc406"
      },
      "source": [
        "# 尝试实验不同大小的数据集\n",
        "num_examples = 10000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset('cmn.txt', num_examples)\n",
        "\n",
        "# 计算目标张量的最大长度 （max_length）\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<zip object at 0x7f0388afac08>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQvShgKwUAe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ec04cee9-d427-4c41-f372-8c65bba54530"
      },
      "source": [
        "# 采用 80 - 20 的比例切分训练集和验证集\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# 显示长度\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000 8000 2000 2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op2o7FMJUC9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gj9EqnEUE5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "66600bde-7008-4e20-f563-97300e3d5868"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "6 ----> 你\n",
            "14 ----> 們\n",
            "45 ----> 得\n",
            "76 ----> 走\n",
            "5 ----> 了\n",
            "3 ----> 。\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "5 ----> you\n",
            "72 ----> need\n",
            "9 ----> to\n",
            "35 ----> go\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYZtsNh_UT8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXSkXu-NUWRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b006830-4f46-457d-cd67-6708f52470e6"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 18]), TensorShape([64, 13]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbaPGnTuUbzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPByyqmVUdk7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d688831b-7510-4641-e771-3dc681cb68b1"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# 样本输入\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 18, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkyCrHj0UgWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # 隐藏层的形状 == （批大小，隐藏层大小）\n",
        "    # hidden_with_time_axis 的形状 == （批大小，1，隐藏层大小）\n",
        "    # 这样做是为了执行加法以计算分数  \n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # 分数的形状 == （批大小，最大长度，1）\n",
        "    # 我们在最后一个轴上得到 1， 因为我们把分数应用于 self.V\n",
        "    # 在应用 self.V 之前，张量的形状是（批大小，最大长度，单位）\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # 注意力权重 （attention_weights） 的形状 == （批大小，最大长度，1）\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # 上下文向量 （context_vector） 求和之后的形状 == （批大小，隐藏层大小）\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt_Z_kcqUiMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "23ee4da3-4c5b-44e5-9353-7696b09fd91e"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 18, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61Z19VeXUk4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # 用于注意力\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # 编码器输出 （enc_output） 的形状 == （批大小，最大长度，隐藏层大小）\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x 在通过嵌入层后的形状 == （批大小，1，嵌入维度）\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x 在拼接 （concatenation） 后的形状 == （批大小，1，嵌入维度 + 隐藏层大小）\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # 将合并后的向量传送到 GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # 输出的形状 == （批大小 * 1，隐藏层大小）\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # 输出的形状 == （批大小，vocab）\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPrDjthAUnNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe9bed1d-420d-4f0f-91ac-9b61cb8774ed"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 3348)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OseKAvmsUoJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXc2LO1XUp0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xb-_SeDUuTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # 教师强制 - 将目标词作为下一个输入\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # 将编码器输出 （enc_output） 传送至解码器\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # 使用教师强制\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gor5dO_7UwAZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "3fd98ff9-abb6-4a83-bf70-aaa6ee541de0"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "  # 每 2 个周期（epoch），保存（检查点）一次模型\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.3221\n",
            "Epoch 1 Batch 100 Loss 2.2094\n",
            "Epoch 1 Loss 2.4897\n",
            "Time taken for 1 epoch 551.1045336723328 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.1100\n",
            "Epoch 2 Batch 100 Loss 1.8320\n",
            "Epoch 2 Loss 1.9157\n",
            "Time taken for 1 epoch 525.9320185184479 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.7396\n",
            "Epoch 3 Batch 100 Loss 1.6935\n",
            "Epoch 3 Loss 1.6901\n",
            "Time taken for 1 epoch 534.1234426498413 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.7066\n",
            "Epoch 4 Batch 100 Loss 1.4734\n",
            "Epoch 4 Loss 1.4738\n",
            "Time taken for 1 epoch 535.869875907898 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.3197\n",
            "Epoch 5 Batch 100 Loss 1.2496\n",
            "Epoch 5 Loss 1.2614\n",
            "Time taken for 1 epoch 536.9471361637115 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 1.0935\n",
            "Epoch 6 Batch 100 Loss 1.2003\n",
            "Epoch 6 Loss 1.0647\n",
            "Time taken for 1 epoch 543.1304533481598 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.8065\n",
            "Epoch 7 Batch 100 Loss 0.8200\n",
            "Epoch 7 Loss 0.8843\n",
            "Time taken for 1 epoch 536.8353803157806 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.7153\n",
            "Epoch 8 Batch 100 Loss 0.8107\n",
            "Epoch 8 Loss 0.7179\n",
            "Time taken for 1 epoch 527.1103324890137 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.6273\n",
            "Epoch 9 Batch 100 Loss 0.6242\n",
            "Epoch 9 Loss 0.5678\n",
            "Time taken for 1 epoch 532.8842859268188 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.3963\n",
            "Epoch 10 Batch 100 Loss 0.4614\n",
            "Epoch 10 Loss 0.4414\n",
            "Time taken for 1 epoch 523.5912392139435 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8YwcLjRU3-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence_zh(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # 存储注意力权重以便后面制图\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # 预测的 ID 被输送回模型\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S20pmARmwdkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#coding:utf-8\n",
        "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
        "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdu6okIltcaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 注意力权重制图函数\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIYJLfzktiaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lI51K7jtkfs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d55ca53e-319d-4a32-db7c-06c52288be30"
      },
      "source": [
        "# 恢复检查点目录 （checkpoint_dir） 中最新的检查点\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f037d89c080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzvLNycjtmzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c425af7d-d058-48ca-db1b-10142fa0266e"
      },
      "source": [
        "translate(u\"这是真的吗\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> 这 是 真的 吗 <end>\n",
            "Predicted translation: it s it true ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 36825 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 26159 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 30495 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 30340 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21527 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 36825 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 26159 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 30495 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 30340 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21527 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}